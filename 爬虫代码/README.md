# 爬虫代码

> ! 注意，使用爬虫代码需要有一定的爬虫知识，特别要熟悉如何设置代理ip，不然无法正常运行代码

爬取数据源自Boss和猎聘，无登录

** 如果只是需要数据，可以在data文件夹里下载，处理后的数据

## 代码运行步骤（含数据处理）

1. 运行以“_爬虫”结尾的文件，运行爬虫
   > 爬虫运行只有第一步，后续是数据处理，可以根据需求自主选择
   >
2. 处理数据
   1. 运行process_xx.py，进行数据处理
   2. 运行merge.py，进行第一次数据合并（分别合并两个网站的数据）
      > merge.py一次只能合并一个网站，实际运行时注意修改代码
      >
   3. 运行salary_process.py，对薪资数据进行处理
      > 同merge.py一样，salary_process.py一次只合并一个网站，注意修改代码
      >
   4. 运行process_xx_2.py，进行数据处理，统一关键词的大小写
   5. 运行merge_all.py把处理好的数据合并为同一个文件
